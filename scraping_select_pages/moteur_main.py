"""
Scraper dÃ©taillÃ© pour le site moteur.ma - Script d'extraction de donnÃ©es automobiles

Ce script permet d'extraire des informations dÃ©taillÃ©es sur les annonces de vÃ©hicules depuis le site moteur.ma.
Il utilise Selenium pour naviguer sur le site et rÃ©cupÃ©rer les donnÃ©es complÃ¨tes de chaque annonce.

FonctionnalitÃ©s principales:
- Extraction des caractÃ©ristiques dÃ©taillÃ©es des vÃ©hicules (kilomÃ©trage, marque, modÃ¨le, etc.)
- TÃ©lÃ©chargement des images associÃ©es Ã  chaque annonce
- Organisation des donnÃ©es dans un fichier CSV structurÃ©
- CrÃ©ation d'une arborescence de dossiers pour stocker les images par annonce

Le script fonctionne en deux phases:
1. Lecture d'un fichier CSV contenant les donnÃ©es de base des annonces (gÃ©nÃ©rÃ© par un scraper initial)
2. Visite de chaque page d'annonce pour extraire les informations dÃ©taillÃ©es et les images

Utilisation:
- ExÃ©cuter le script et spÃ©cifier la plage de pages concernÃ©e
- Les rÃ©sultats sont enregistrÃ©s dans ../data/moteur/
"""
import os
import re
import requests
import unicodedata
import time
import csv
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager

def setup_driver():
    """Configure et initialise le driver Selenium."""
    options = Options()
    options.add_argument("--headless")  # ExÃ©cuter sans interface graphique
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-blink-features=AutomationControlled")  # Contourner la dÃ©tection des bots
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    return driver

def sanitize_filename(filename):
    """Nettoie un nom de fichier pour qu'il soit valide sur le systÃ¨me d'exploitation."""
    # Remplacer les caractÃ¨res non-alphanumÃ©riques par des underscores
    filename = re.sub(r'[^\w\s-]', '_', filename)
    # Normaliser les caractÃ¨res accentuÃ©s
    filename = unicodedata.normalize('NFKD', filename).encode('ASCII', 'ignore').decode('ASCII')
    # Remplacer les espaces par des underscores
    filename = re.sub(r'\s+', '_', filename)
    return filename

def download_image(url, folder_path, index):
    """TÃ©lÃ©charge une image Ã  partir d'une URL avec des en-tÃªtes amÃ©liorÃ©s."""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    try:
        print(f"TÃ©lÃ©chargement de {url} vers {folder_path}")
        response = requests.get(url, headers=headers, timeout=15)
        if response.status_code == 200:
            file_extension = url.split('.')[-1]
            if '?' in file_extension:
                file_extension = file_extension.split('?')[0]
            if not file_extension or len(file_extension) > 5:
                file_extension = "jpg"  # Extension par dÃ©faut si problÃ¨me
            image_path = os.path.join(folder_path, f"image_{index}.{file_extension}")
            with open(image_path, 'wb') as f:
                f.write(response.content)
            print(f"âœ… Image enregistrÃ©e : {image_path}")
            return True
        else:
            print(f"âŒ Erreur HTTP {response.status_code} pour {url}")
        return False
    except Exception as e:
        print(f"âš ï¸ Erreur lors du tÃ©lÃ©chargement de l'image {url}: {e}")
        return False

def scrape_detail_page(driver, url, ad_id, title, price_from_csv, folder_name):
    """Scrape les dÃ©tails d'une annonce spÃ©cifique avec la nouvelle structure HTML."""
    try:
        # AccÃ©der Ã  la page de dÃ©tail
        driver.get(url)
        time.sleep(3)  # Attendre le chargement de la page
        
        # CrÃ©er un dossier pour les images de cette annonce
        images_base_folder = os.path.join("..", "data", "moteur", "images")
        os.makedirs(images_base_folder, exist_ok=True)
        
        folder_path = os.path.join(images_base_folder, folder_name)
        if not os.path.exists(folder_path):
            os.makedirs(folder_path)
            print(f"ğŸ“‚ Dossier crÃ©Ã© : {folder_path}")
        
        # Initialiser avec des valeurs par dÃ©faut
        location = "N/A"
        mileage = "N/A"
        brand = "N/A"
        model = "N/A"
        doors = "N/A"
        # origin supprimÃ©
        first_hand = "N/A"
        fiscal_power = "N/A"
        # condition supprimÃ©
        equipment_text = "N/A"
        seller_city = "N/A"
        dedouane = "N/A"
        transmission = "N/A"  # Important: initialiser la transmission
        fuel_type = "N/A"
        creator = "N/A"  # Initialiser le crÃ©ateur
        
        # Extraction du crÃ©ateur
        try:
            # Rechercher le lien avec l'icÃ´ne "megaphone"
            creator_element = driver.find_element(By.XPATH, "//a[contains(., 'icon-normal-megaphone')]")
            if creator_element:
                creator = creator_element.text.strip()
            
            # Si la mÃ©thode ci-dessus Ã©choue, essayer une autre approche
            if creator == "N/A":
                creator_element = driver.find_element(By.XPATH, "//div[@class='actions block_tele']//li/a[i[contains(@class, 'icon-normal-megaphone')]]")
                creator = creator_element.text.strip()
        except Exception as e:
            print(f"Erreur extraction du crÃ©ateur: {e}")
            # TroisiÃ¨me tentative avec un XPath plus prÃ©cis
            try:
                creator_element = driver.find_element(By.XPATH, "//div[@class='block-inner block-detail-ad']//div[@class='actions block_tele']//a[contains(@href, 'stock-professionnel')]")
                creator = creator_element.text.strip()
            except Exception as e2:
                print(f"Erreur extraction du crÃ©ateur (mÃ©thode alternative): {e2}")
        
        # Extraction de la transmission
        try:
            transmission_element = driver.find_element(By.XPATH, "//span[contains(text(), 'Boite de vitesses')]/following-sibling::span")
            transmission = transmission_element.text.strip()
        except Exception as e:
            print(f"Erreur extraction directe de transmission: {e}")
            transmission = "N/A"  # Garde la valeur par dÃ©faut si Ã©chec
        
        # RÃ©cupÃ©rer les dÃ©tails du vÃ©hicule - PROCÃ‰DER AVEC LA MÃ‰THODE HABITUELLE
        detail_lines = driver.find_elements(By.CLASS_NAME, "detail_line")
        
        for line in detail_lines:
            try:
                line_text = line.text.strip()
                spans = line.find_elements(By.TAG_NAME, "span")
                if len(spans) >= 2:
                    key = spans[0].text.strip()
                    value = spans[1].text.strip()
                    
                    if "KilomÃ©trage" in key:
                        mileage = value
                    elif "AnnÃ©e" in key:
                        pass
                    elif "Boite de vitesses" in key:
                        transmission = value
                    elif "Carburant" in key:
                        fuel_type = value
                    elif "Puissance fiscale" in key:
                        fiscal_power = value
                    elif "Nombre de portes" in key:
                        doors = value
                    elif "PremiÃ¨re main" in key:
                        first_hand = value
                    elif "VÃ©hicule dÃ©douanÃ©" in key:
                        dedouane = value
                    # Suppression de la condition "Ã‰tat"
            except Exception as e:
                print(f"Erreur lors de l'extraction d'une ligne de dÃ©tail: {e}")
        
        # Extraction des Ã©quipements au lieu de la description
        try:
            equipment_elements = driver.find_elements(By.CSS_SELECTOR, "div.option_ad")
            equipment_list = []
            for element in equipment_elements:
                # Extraire le texte sans le symbole âœ”
                equipment_text = element.text.strip()
                if equipment_text.startswith("âœ”"):
                    equipment_text = equipment_text[1:].strip()
                equipment_list.append(equipment_text)
            
            # Joindre tous les Ã©quipements en une chaÃ®ne sÃ©parÃ©e par des virgules
            equipment_text = ", ".join(equipment_list)
        except Exception as e:
            print(f"Erreur extraction Ã©quipements: {e}")
            equipment_text = "N/A"
        
        # Extraction de la ville
        try:
            city_element = driver.find_element(By.XPATH, "//a[contains(@href, 'ville')]")
            seller_city = city_element.text.strip()
            location = seller_city
        except Exception as e:
            print(f"Erreur extraction ville: {e}")
        
        # Extraction des images
        image_count = 0
        try:
            image_elements = driver.find_elements(By.CSS_SELECTOR, "img[data-u='image']")
            for index, img in enumerate(image_elements):
                img_url = img.get_attribute("src")
                if img_url and "http" in img_url:
                    success = download_image(img_url, folder_path, index + 1)
                    if success:
                        image_count += 1
        except Exception as e:
            print(f"Erreur lors de l'extraction des images: {e}")
        
        # Extraction de la marque et du modÃ¨le depuis le titre
        try:
            title_parts = title.split()
            if len(title_parts) >= 2:
                brand = title_parts[0].upper()
                model = title_parts[1].capitalize()
        except Exception as e:
            print(f"Erreur lors de l'extraction de la marque et du modÃ¨le depuis le titre: {e}")
        
        # Retourner les dÃ©tails sans origine et condition
        return location, mileage, brand, model, doors, first_hand, fiscal_power, equipment_text, seller_city, folder_name, dedouane, transmission, creator
        
    except Exception as e:
        print(f"âŒ Erreur lors du scraping de la page {url}: {e}")
        return ["N/A"] * 12 + ["N/A"]  # Retourner des valeurs par dÃ©faut en cas d'erreur (nombre ajustÃ©)
def load_basic_data(input_file):
    """Charge les donnÃ©es de base depuis le fichier CSV."""
    data = []
    try:
        with open(input_file, 'r', encoding='utf-8-sig') as f:
            reader = csv.reader(f)
            next(reader)  # Ignorer l'en-tÃªte
            for row in reader:
                data.append(row)
        return data
    except Exception as e:
        print(f"âŒ Erreur lors du chargement des donnÃ©es de base: {e}")
        return None

def process_detailed_data(basic_data, output_file):
    """Traite les donnÃ©es de base pour obtenir des informations dÃ©taillÃ©es pour chaque annonce."""
    driver = setup_driver()

    # Nouveaux en-tÃªtes sans "Origine" et "Ã‰tat"
    new_headers = [
        "ID", "Titre", "Prix", "Date de publication", "Type de carburant", "Transmission", "CrÃ©ateur",
        "Secteur", "KilomÃ©trage", "Marque", "ModÃ¨le", "Nombre de portes", 
        "PremiÃ¨re main", "Puissance fiscale", "Ã‰quipements", "Ville du vendeur", "Dossier d'images", "DÃ©douanÃ©"
    ]
    
    detailed_data = [new_headers]  # Utiliser les nouveaux en-tÃªtes

    for idx, row in enumerate(basic_data, start=1):
        try:
            ad_id = row[0]  # ID est Ã  l'index 0
            title = row[1]  # Titre est Ã  l'index 1
            price = row[2]  # Prix est Ã  l'index 2
            year = row[3]   # AnnÃ©e est Ã  l'index 3
            fuel_type = row[4]  # Type de carburant est Ã  l'index 4
            city = row[5]   # Ville est Ã  l'index 5
            url = row[6]    # URL est Ã  l'index 6 (Lien)
            
            # CrÃ©er un nom de dossier unique pour les images
            folder_name = f"{ad_id}_{sanitize_filename(title)}"
            
            # Appeler la fonction de scraping dÃ©taillÃ© qui retourne maintenant sans origine et condition
            car_details = scrape_detail_page(driver, url, ad_id, title, price, folder_name)
            
            # Extraire la transmission et le crÃ©ateur des rÃ©sultats retournÃ©s
            transmission = car_details[11] if len(car_details) > 11 else "N/A"  # Index ajustÃ©
            creator = car_details[12] if len(car_details) > 12 else "N/A"  # Index ajustÃ©
            
            # CrÃ©er une ligne de donnÃ©es combinÃ©e avec la structure modifiÃ©e (sans origine et Ã©tat)
            combined_data = [
                ad_id, title, price, year, fuel_type, transmission, creator,
                car_details[0], car_details[1], car_details[2], car_details[3],
                car_details[4], car_details[5], car_details[6], car_details[7], 
                car_details[8], car_details[9], car_details[10]
            ]
            
            detailed_data.append(combined_data)
            print(f"âœ… Traitement de l'annonce {idx} terminÃ©. CrÃ©ateur: {creator}")
            
        except Exception as e:
            print(f"âŒ Erreur lors du traitement de l'annonce {idx}: {e}")

    driver.quit()

    # Enregistrer les dÃ©tails extraits
    print(f"ğŸ“‚ Enregistrement du fichier CSV dÃ©taillÃ© dans : {output_file}")
    try:
        with open(output_file, "w", newline="", encoding="utf-8-sig") as file:
            writer = csv.writer(file)
            writer.writerows(detailed_data)

        print(f"âœ… Fichier CSV dÃ©taillÃ© sauvegardÃ© dans {output_file}")
    except Exception as e:
        print(f"âŒ Erreur lors de l'enregistrement des dÃ©tails : {e}")

def get_page_range():
    """Demander Ã  l'utilisateur de spÃ©cifier la plage de pages Ã  utiliser pour le nom du fichier."""
    while True:
        try:
            print("\nVeuillez spÃ©cifier la plage de pages du fichier Ã  utiliser:")
            start_page = int(input("Page de dÃ©but: "))
            end_page = int(input("Page de fin: "))
            
            if start_page <= 0 or end_page <= 0:
                print("âš ï¸ Les numÃ©ros de page doivent Ãªtre positifs.")
                continue
                
            if start_page > end_page:
                print("âš ï¸ La page de dÃ©but doit Ãªtre infÃ©rieure ou Ã©gale Ã  la page de fin.")
                continue
                
            return start_page, end_page
        except ValueError:
            print("âš ï¸ Veuillez entrer des nombres valides.")

def main():
    """Fonction principale pour exÃ©cuter le scraper dÃ©taillÃ©."""
    print("ğŸš— DÃ©marrage du scraper d'annonces moteur.ma - Phase de dÃ©tail...")
    
    # Demander la plage de pages pour le nom du fichier
    start_page, end_page = get_page_range()
    
    # Construire le nom du fichier d'entrÃ©e
    input_filename = f"moteur_listings_p{start_page}-p{end_page}.csv"
    input_file = os.path.join("..", "data", "moteur", input_filename)
    
    # VÃ©rifier si le fichier existe
    if not os.path.exists(input_file):
        print(f"âŒ Le fichier {input_file} n'existe pas!")
        print("Veuillez vÃ©rifier que vous avez bien exÃ©cutÃ© le scraper initial avec les mÃªmes pages.")
        return
    
    # GÃ©nÃ©rer le nom du fichier de sortie
    output_filename = f"moteur_details_p{start_page}-p{end_page}.csv"
    output_file = os.path.join("..", "data", "moteur", output_filename)
    
    print(f"\nğŸ“‹ Lecture du fichier d'entrÃ©e: {input_file}")
    print(f"ğŸ“ Le fichier de sortie sera: {output_file}")
    
    # Charger les donnÃ©es de base
    basic_data = load_basic_data(input_file)
    
    if basic_data is None or len(basic_data) == 0:
        print("âŒ Aucune donnÃ©e trouvÃ©e dans le fichier d'entrÃ©e. ArrÃªt du programme.")
        return
    
    print(f"âœ… {len(basic_data)} annonces chargÃ©es depuis le fichier de donnÃ©es de base.")
    
    # Traiter les donnÃ©es dÃ©taillÃ©es
    print("\nğŸ” Collecte d'informations dÃ©taillÃ©es et tÃ©lÃ©chargement d'images pour chaque annonce...")
    process_detailed_data(basic_data, output_file)
    
    print("\nâœ… SCRAPING DÃ‰TAILLÃ‰ TERMINÃ‰ AVEC SUCCÃˆS!")
    print(f"Informations dÃ©taillÃ©es enregistrÃ©es dans: {output_file}")
    print(f"Images tÃ©lÃ©chargÃ©es dans: ../data/moteur/images/[dossiers_annonces]")

if __name__ == "__main__":
    main()